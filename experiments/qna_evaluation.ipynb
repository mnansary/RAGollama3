{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_csv_path=\"/home/vpa/RAGollama3/data/20241006/source.csv\"\n",
    "qna_csv_path=\"/home/vpa/RAGollama3/data/20241006/formatted.csv\"\n",
    "MODEL_NAME=\"llama3.1:70b\"       \n",
    "MODEL_BASE_URL='http://localhost:11434'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "passages=pd.read_csv(passage_csv_path)[\"passage\"].tolist()\n",
    "df=pd.read_csv(qna_csv_path)[['question', 'answer',  'passage_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import  tqdm \n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "template = \"\"\"You are a knowledgeable chatbot, designed to assist users with their inquiries in a detailed and informative manner. \n",
    "            Your responses should only answer the user's questions . \n",
    "            Ensure your tone is professional, yet approachable, and remember to communicate in Bengali (বাংলা).\n",
    "\n",
    "            Context: {}\n",
    "\n",
    "            User: {}\n",
    "            Chatbot: Please provide precise humanly response.\n",
    "            \"\"\"\n",
    "\n",
    "llm = Ollama(\n",
    "        base_url=MODEL_BASE_URL,\n",
    "        model=MODEL_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for idx in tqdm(range(len(df))):\n",
    "    question=df.iloc[idx,1]\n",
    "    context=passages[df.iloc[idx,-1]]\n",
    "    prompt=template.format(context,question)\n",
    "    results.append(llm(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"model_response\"]=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"model_response_evaluation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
